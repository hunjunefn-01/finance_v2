import pandas as pd
import numpy as np
import re
import os
from pathlib import Path

# --- 1. í™˜ê²½ ì„¤ì • ë° í‘œì¤€ í—¤ë” ì •ì˜ ---
STANDARD_HEADERS = [
    'ì¶œì²˜', 'ê±°ë˜_ì¼ì‹œ', 'ê±°ë˜_ìœ í˜•', 'ê±°ë˜_ìƒëŒ€ë°©/ê°€ë§¹ì ', 
    'ì¶œê¸ˆ_ê¸ˆì•¡', 'ì…ê¸ˆ_ê¸ˆì•¡', 'ì”ì•¡', 'ìƒì„¸_ì •ë³´'
]

# ì¶œì²˜(Source Name)ì™€ íŒŒì¼ëª… ë§¤í•‘ (ì‚¬ìš©ì ì‹¤í–‰ ë¡œê·¸ ë°˜ì˜)
FILE_MAPPING = {
    'ì¼€ì´': 'ì¼€ì´ë±…í¬.tsv',
    'í† ìŠ¤': 'í† ìŠ¤ë±…í¬.tsv',
    'ì‹ í•œ': 'ì‹ í•œì€í–‰.tsv',
    'ì¹´ì¹´ì˜¤': 'ì¹´ì¹´ì˜¤ë±…í¬.tsv',
    'í˜„ëŒ€': 'í˜„ëŒ€ì¹´ë“œ.tsv',
    'ë†í˜‘_í˜œì§„': 'ë†í˜‘_í˜œì§„.tsv', # 'ì¶”ê°€'ë¥¼ 'ë†í˜‘_í˜œì§„'ìœ¼ë¡œ ë°˜ì˜
}

# í”„ë¡œì íŠ¸ ê²½ë¡œ í™•ì¸ ë° ë””ë ‰í† ë¦¬ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parent.parent
DATA_DIR_PATH = PROJECT_ROOT / 'data'
LOG_DIR_PATH = PROJECT_ROOT / 'log'

# ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ì„ ê²½ìš°)
os.makedirs(DATA_DIR_PATH, exist_ok=True)
os.makedirs(LOG_DIR_PATH, exist_ok=True)

# ê¸ˆì•¡/ì”ì•¡ ì»¬ëŸ¼ ì´ë¦„ ì •ì˜ (clean_amount ì¼ê´„ ì ìš©ì„ ìœ„í•´ ì‚¬ìš©)
AMOUNT_COLS_MAP = {
    'ì¼€ì´': ['ì…ê¸ˆê¸ˆì•¡', 'ì¶œê¸ˆê¸ˆì•¡', 'ì”ì•¡'],
    'í† ìŠ¤': ['ê±°ë˜ ê¸ˆì•¡', 'ê±°ë˜ í›„ ì”ì•¡'],
    'ì‹ í•œ': ['ì…ê¸ˆ', 'ì¶œê¸ˆ', 'ì”ì•¡'],
    'ì¹´ì¹´ì˜¤': ['ê±°ë˜ê¸ˆì•¡', 'ê±°ë˜ í›„ ì”ì•¡'],
    'í˜„ëŒ€': ['ì´ìš©ê¸ˆì•¡'],
    'ë†í˜‘_í˜œì§„': ['ì¶œê¸ˆê¸ˆì•¡', 'ì…ê¸ˆê¸ˆì•¡', 'ê±°ë˜í›„ì”ì•¡'] # 'ë†í˜‘_í˜œì§„' ë°˜ì˜
}


# --- 2. ìœ í‹¸ í•¨ìˆ˜ ì •ì˜ ---

def clean_amount(series: pd.Series) -> pd.Series:
    """ê¸ˆì•¡/ì”ì•¡ ë¬¸ìì—´ì—ì„œ ì‰¼í‘œ, í†µí™” ê¸°í˜¸ë¥¼ ì œê±°í•˜ê³  Int64ë¡œ ë³€í™˜"""
    # ìˆ«ì, ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ë¥¼ ì œì™¸í•œ ëª¨ë“  ë¬¸ì ì œê±°
    cleaned = series.astype(str).str.replace(r'[^0-9\.\-]+', '', regex=True)
    
    # Int64 íƒ€ì… (NaN ì§€ì›)ìœ¼ë¡œ ë³€í™˜
    return pd.to_numeric(cleaned, errors='coerce').astype('Int64')


# --- 3. íŒŒì¼ë³„ ë³€í™˜ ë¡œì§ ---

def process_file(source_name: str) -> pd.DataFrame | None:
    """ê°œë³„ TSV íŒŒì¼ì„ ì½ì–´ í‘œì¤€í™”ëœ DataFrameìœ¼ë¡œ ë³€í™˜"""
    try:
        file_path = DATA_DIR_PATH / FILE_MAPPING[source_name]
        df = pd.read_csv(file_path, sep='\t', encoding='utf-8')
        print(f"[{source_name}] íŒŒì¼ ì½ê¸° ì‹œì‘: {file_path}")
    except Exception as e:
        print(f"âš ï¸ [{source_name}] íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

    # 1. í‘œì¤€ DataFrame ì´ˆê¸°í™” ë° 'ì¶œì²˜' ë‹¨ì¼ í• ë‹¹
    standard_df = pd.DataFrame(columns=STANDARD_HEADERS, index=df.index)
    standard_df['ì¶œì²˜'] = source_name
    
    # 2. ê³µí†µ ê¸ˆì•¡/ì”ì•¡ ì»¬ëŸ¼ ì „ì²˜ë¦¬
    if source_name in AMOUNT_COLS_MAP:
        for col in AMOUNT_COLS_MAP[source_name]:
            if col in df.columns:
                df[col] = clean_amount(df[col])


    # 3. ë°ì´í„° ë³€í™˜ ë° ë§¤í•‘ (ê° ê¸ˆìœµê¸°ê´€ë³„ ë¡œì§)
    
    # --- A. ì¼€ì´ë±…í¬ ---
    if source_name == 'ì¼€ì´':
        standard_df['ê±°ë˜_ì¼ì‹œ'] = pd.to_datetime(df['ê±°ë˜ì¼ì‹œ'], format='%Y.%m.%d %H:%M:%S', errors='coerce')
        standard_df['ê±°ë˜_ìœ í˜•'] = df['ê±°ë˜êµ¬ë¶„'].fillna('')
        standard_df['ê±°ë˜_ìƒëŒ€ë°©/ê°€ë§¹ì '] = df['ì ìš”ë‚´ìš©'].fillna(df['ìƒëŒ€ ì˜ˆê¸ˆì£¼ëª…']).fillna('')
        standard_df['ì¶œê¸ˆ_ê¸ˆì•¡'] = df['ì¶œê¸ˆê¸ˆì•¡'].fillna(0)
        standard_df['ì…ê¸ˆ_ê¸ˆì•¡'] = df['ì…ê¸ˆê¸ˆì•¡'].fillna(0)
        standard_df['ì”ì•¡'] = df['ì”ì•¡']
        
        details = df[['ìƒëŒ€ ì€í–‰', 'ìƒëŒ€ ê³„ì¢Œë²ˆí˜¸', 'ë©”ëª¨']].astype(str).fillna('').agg(
            lambda x: ', '.join(x[x != '']), axis=1
        ).str.replace(r',\s*$', '', regex=True)
        standard_df['ìƒì„¸_ì •ë³´'] = details

        
    # --- B. í† ìŠ¤ë±…í¬ ---
    elif source_name == 'í† ìŠ¤':
        standard_df['ê±°ë˜_ì¼ì‹œ'] = pd.to_datetime(df['ê±°ë˜ ì¼ì‹œ'], format='%Y.%m.%d %H:%M:%S', errors='coerce')
        standard_df['ê±°ë˜_ìœ í˜•'] = df['ê±°ë˜ ìœ í˜•'] + ' (' + df['ì ìš”'] + ')'
        standard_df['ê±°ë˜_ìƒëŒ€ë°©/ê°€ë§¹ì '] = df['ì ìš”']
        standard_df['ì¶œê¸ˆ_ê¸ˆì•¡'] = df['ê±°ë˜ ê¸ˆì•¡'].apply(lambda x: abs(x) if x < 0 else 0)
        standard_df['ì…ê¸ˆ_ê¸ˆì•¡'] = df['ê±°ë˜ ê¸ˆì•¡'].apply(lambda x: x if x > 0 else 0)
        standard_df['ì”ì•¡'] = df['ê±°ë˜ í›„ ì”ì•¡']
        
        details = df[['ê±°ë˜ ê¸°ê´€', 'ê³„ì¢Œë²ˆí˜¸', 'ë©”ëª¨']].astype(str).fillna('').agg(
            lambda x: ', '.join(x[x != '']), axis=1
        ).str.replace(r',\s*$', '', regex=True)
        standard_df['ìƒì„¸_ì •ë³´'] = details

        
    # --- C. ì‹ í•œì€í–‰ ---
    elif source_name == 'ì‹ í•œ':
        df.columns = df.columns.str.replace(r'\(ì›\)', '', regex=True).str.strip()
        
        standard_df['ê±°ë˜_ì¼ì‹œ'] = pd.to_datetime(df['ê±°ë˜ì¼ì'] + ' ' + df['ê±°ë˜ì‹œê°„'], format='%Y-%m-%d %H:%M:%S', errors='coerce')
        standard_df['ê±°ë˜_ìœ í˜•'] = df['ì ìš”']
        standard_df['ê±°ë˜_ìƒëŒ€ë°©/ê°€ë§¹ì '] = df['ë‚´ìš©']
        standard_df['ì¶œê¸ˆ_ê¸ˆì•¡'] = df['ì¶œê¸ˆ'].fillna(0)
        standard_df['ì…ê¸ˆ_ê¸ˆì•¡'] = df['ì…ê¸ˆ'].fillna(0)
        standard_df['ì”ì•¡'] = df['ì”ì•¡']
        standard_df['ìƒì„¸_ì •ë³´'] = df['ê±°ë˜ì '].astype(str).fillna('')

        
    # --- D. ì¹´ì¹´ì˜¤ë±…í¬ ---
    elif source_name == 'ì¹´ì¹´ì˜¤':
        standard_df['ê±°ë˜_ì¼ì‹œ'] = pd.to_datetime(df['ê±°ë˜ì¼ì‹œ'], format='%Y.%m.%d %H:%M:%S', errors='coerce')
        standard_df['ê±°ë˜_ìœ í˜•'] = df['êµ¬ë¶„'] + ' (' + df['ê±°ë˜êµ¬ë¶„'] + ')'
        standard_df['ê±°ë˜_ìƒëŒ€ë°©/ê°€ë§¹ì '] = df['ë‚´ìš©']
        standard_df['ì¶œê¸ˆ_ê¸ˆì•¡'] = df['ê±°ë˜ê¸ˆì•¡'].apply(lambda x: abs(x) if x < 0 else 0)
        standard_df['ì…ê¸ˆ_ê¸ˆì•¡'] = df['ê±°ë˜ê¸ˆì•¡'].apply(lambda x: x if x > 0 else 0)
        standard_df['ì”ì•¡'] = df['ê±°ë˜ í›„ ì”ì•¡']
        standard_df['ìƒì„¸_ì •ë³´'] = df['ë©”ëª¨'].astype(str).fillna('')
        
        
    # --- E. í˜„ëŒ€ì¹´ë“œ ---
    elif source_name == 'í˜„ëŒ€':
        date_str = df['ì´ìš©ì¼'].str.replace(r'[ë…„ì›”ì¼]', '-', regex=True).str.strip('-')
        standard_df['ê±°ë˜_ì¼ì‹œ'] = pd.to_datetime(date_str, format='%Y-%m-%d', errors='coerce')
        
        standard_df['ê±°ë˜_ìœ í˜•'] = 'ì¹´ë“œê²°ì œ (' + df['ì¹´ë“œêµ¬ë¶„'] + ')'
        standard_df['ê±°ë˜_ìƒëŒ€ë°©/ê°€ë§¹ì '] = df['ê°€ë§¹ì ëª…']
        standard_df['ì¶œê¸ˆ_ê¸ˆì•¡'] = df['ì´ìš©ê¸ˆì•¡'].fillna(0)
        standard_df['ì…ê¸ˆ_ê¸ˆì•¡'] = 0
        standard_df['ì”ì•¡'] = pd.NA
        
        details = df[['í™•ì •ì¼', 'ì¹´ë“œëª…(ì¹´ë“œë²ˆí˜¸ ë’¤ 4ìë¦¬)', 'ì‚¬ì—…ìë²ˆí˜¸', 'ìŠ¹ì¸ë²ˆí˜¸', 'í• ë¶€ ê°œì›”']].astype(str).fillna('').agg(
            lambda x: ', '.join(x[x != '']), axis=1
        ).str.replace(r',\s*$', '', regex=True)
        standard_df['ìƒì„¸_ì •ë³´'] = details

        
    # --- F. ë†í˜‘_í˜œì§„ ë°ì´í„° ---
    elif source_name == 'ë†í˜‘_í˜œì§„':
        try:
            standard_df['ê±°ë˜_ì¼ì‹œ'] = pd.to_datetime(
                df['ê±°ë˜ì¼ì‹œ'].str.replace(r'\s+', ' ', regex=True).str.strip(), 
                format='%Y/%m/%d %H:%M:%S', 
                errors='coerce'
            )
        except Exception:
            standard_df['ê±°ë˜_ì¼ì‹œ'] = df['ê±°ë˜ì¼ì‹œ']
            
        standard_df['ê±°ë˜_ìƒëŒ€ë°©/ê°€ë§¹ì '] = df['ê±°ë˜ë‚´ìš©'].fillna('')
        
        standard_df['ê±°ë˜_ìœ í˜•'] = np.where(
            pd.notna(df['ì¶œê¸ˆê¸ˆì•¡']) & (df['ì¶œê¸ˆê¸ˆì•¡'] > 0), 
            'ì¶œê¸ˆ',
            np.where(
                pd.notna(df['ì…ê¸ˆê¸ˆì•¡']) & (df['ì…ê¸ˆê¸ˆì•¡'] > 0), 
                'ì…ê¸ˆ', 
                'ê¸°íƒ€'
            )
        )
        
        standard_df['ì¶œê¸ˆ_ê¸ˆì•¡'] = df['ì¶œê¸ˆê¸ˆì•¡'].fillna(0)
        standard_df['ì…ê¸ˆ_ê¸ˆì•¡'] = df['ì…ê¸ˆê¸ˆì•¡'].fillna(0)
        standard_df['ì”ì•¡'] = df['ê±°ë˜í›„ì”ì•¡']
        
        details = df[['ê±°ë˜ê¸°ë¡ì‚¬í•­', 'ê±°ë˜ì ', 'ê±°ë˜ë©”ëª¨']].astype(str).fillna('').agg(
            lambda x: ', '.join(x[x != '']), axis=1
        ).str.replace(r',\s*$', '', regex=True)
        standard_df['ìƒì„¸_ì •ë³´'] = details
        
    else:
        print(f"âš ï¸ [{source_name}] ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ì¶œì²˜ì…ë‹ˆë‹¤. FILE_MAPPINGì— ë“±ë¡ë˜ì–´ ìˆìœ¼ë‚˜, process_file ë¡œì§ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # 4. ìµœì¢… ì •ì œ ë° ë°˜í™˜
    standard_df = standard_df[STANDARD_HEADERS].dropna(subset=['ê±°ë˜_ì¼ì‹œ']).reset_index(drop=True)
    return standard_df


# --- 4. ë©”ì¸ í†µí•© ì‹¤í–‰ ë¡œì§ ---

def integrate_all_transactions():
    """ëª¨ë“  íŒŒì¼ì„ ì½ì–´ í†µí•© ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥ ë° ì €ì¥"""
    combined_df_list = []
    
    # 4.1. íŒŒì¼ ì²˜ë¦¬ ë£¨í”„
    for source_name in FILE_MAPPING.keys():
        standard_data = process_file(source_name)
        if standard_data is not None and not standard_data.empty:
            combined_df_list.append(standard_data)
    
    # 4.2. ìµœì¢… í†µí•© ë° ì •ë ¬
    if not combined_df_list:
        print("\n**í†µí•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.**")
        return None
        
    final_df = pd.concat(combined_df_list, ignore_index=True)
    # ê±°ë˜ ì¼ì‹œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹ ìˆœ ì •ë ¬
    final_df = final_df.sort_values(by='ê±°ë˜_ì¼ì‹œ', ascending=False).reset_index(drop=True)

    # 4.3. ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
    print("\n" + "="*50)
    print("## âœ… ìµœì¢… í†µí•©ëœ ê¸ˆìœµ ê±°ë˜ ë‚´ì—­ (í‘œì¤€í™” ì™„ë£Œ)")
    print(f"**ì´ ê±°ë˜ ê±´ìˆ˜:** {len(final_df)}ê±´")
    print(f"**í†µí•© ë°ì´í„°ì…‹ì˜ í—¤ë”:** {list(final_df.columns)}")
    print("="*50)
    
    # 4.3.1. TSV íŒŒì¼ë¡œ ì €ì¥ (log í´ë”ì—)
    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
    output_file_name = f'integrated_transactions_{timestamp}.tsv'
    output_path = LOG_DIR_PATH / output_file_name
    
    try:
        # TSV í˜•ì‹ìœ¼ë¡œ ì €ì¥ (sep='\t', index=False)
        final_df.to_csv(output_path, sep='\t', index=False, encoding='utf-8')
        print(f"\n**ğŸ’¾ í†µí•© ë°ì´í„° ì „ì²´ ë‚´ì—­ì„ ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.**")
        print(f"**ì €ì¥ ê²½ë¡œ:** {output_path}")
    except Exception as e:
        print(f"\nâš ï¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    return final_df


if __name__ == "__main__":
    integrated_data = integrate_all_transactions()
    
    if integrated_data is not None:
        print("\n\n*í†µí•©ëœ ë°ì´í„°ë¥¼ ë³€ìˆ˜ 'integrated_data'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.*")