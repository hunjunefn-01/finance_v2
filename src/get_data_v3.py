import re
import os
import pandas as pd
import numpy as np
from pathlib import Path

# ----------------------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# ----------------------------------------------------------------------

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì • (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ {í”„ë¡œì íŠ¸ê²½ë¡œ}/src ë‚´ì— ìˆë‹¤ê³  ê°€ì •)
# __file__ ë³€ìˆ˜ê°€ ì¡´ì¬í•˜ëŠ” ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ê²½ìš°:
# PROJECT_ROOT = Path(__file__).resolve().parent.parent
# (srcì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ê°€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ê°€ ë¨)
# ì¸í„°ë™í‹°ë¸Œ í™˜ê²½ì—ì„œ __file__ì´ ì—†ì„ ê²½ìš°: í˜„ì¬ ê²½ë¡œ(.)ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ê°„ì£¼
PROJECT_ROOT = Path(__file__).resolve().parent.parent if '__file__' in locals() else Path('.')

DATA_DIR_PATH = PROJECT_ROOT / 'data' # ì›ì²œ íŒŒì¼ ê²½ë¡œ
LOG_DIR_PATH = PROJECT_ROOT / 'log' # ë¡œê·¸ ì €ì¥ ê²½ë¡œ
LOG_DIR_PATH.mkdir(exist_ok=True) # ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±

# ContentFetchId ë§¤í•‘ (ì‹¤í–‰ í™˜ê²½ì—ì„œ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‚¬ìš©)
FILE_MAP = {
    "ì¹´ì¹´ì˜¤ë±…í¬": "ì¹´ì¹´ì˜¤ë±…í¬.tsv",
    "ì¼€ì´ë±…í¬": "ì¼€ì´ë±…í¬.tsv",
    "í† ìŠ¤ë±…í¬": "í† ìŠ¤ë±…í¬.tsv",
    "í˜„ëŒ€ì¹´ë“œ": "í˜„ëŒ€ì¹´ë“œ.tsv",
    "ë†í˜‘_í˜œì§„": "ë†í˜‘_í˜œì§„.tsv",
    "ì‹ í•œì€í–‰": "ì‹ í•œì€í–‰.tsv"
}
# ìµœì¢… í†µí•© ì»¬ëŸ¼ (ì´ 9ê°œ)
FINAL_COLUMNS = ['ê±°ë˜ì¼ì‹œ', 'ì‚¬ìš©êµ¬ë¶„', 'ì‚¬ìš©ë‚´ì—­', 'ê±°ë˜ìƒëŒ€ë°©', 'ì…ê¸ˆì•¡', 'ì¶œê¸ˆì•¡', 'ì”ì•¡', 'ë©”ëª¨', 'ì¶œì²˜']


# ----------------------------------------------------------------------
# 2. í—¬í¼ í•¨ìˆ˜ ì •ì˜
# ----------------------------------------------------------------------

def clean_amount(series):
    """ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ ì „, ë¶ˆí•„ìš”í•œ ë¬¸ìë¥¼ ì œê±°í•˜ê³  ìˆ«ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤. (ë¹ˆ ê°’/ë¬¸ìì—´ì€ np.nan ì²˜ë¦¬)"""
    if pd.api.types.is_object_dtype(series.dtype) or pd.api.types.is_string_dtype(series.dtype):
        # ì‰¼í‘œ, 'ì›', ê³µë°± ë“± ì œê±°
        cleaned = series.astype(str).str.replace(r'[,\ì›\s]', '', regex=True)
        # ë¹ˆ ë¬¸ìì—´ì„ np.nanìœ¼ë¡œ ë³€ê²½í•˜ì—¬ float ë³€í™˜ ì‹œ ì˜¤ë¥˜ ë°©ì§€
        return pd.to_numeric(cleaned.replace('', np.nan), errors='coerce')
    return series

def combine_and_clean_str(df, series_names, sep=' '):
    """ì§€ì •ëœ ì»¬ëŸ¼ë“¤ì„ ê²°í•©í•˜ê³ , ê²°ê³¼ê°€ ë¹ˆ ë¬¸ìì—´ì´ë©´ pd.NAë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    series_to_combine = []
    for name in series_names:
        if name in df.columns:
            # ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  NaN/Noneì„ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´ (pd.NAë¡œ ëŒ€ì²´ ì‹œ 'nan' ë¬¸ìì—´ ë°©ì§€)
            s = df[name].astype(str).replace({'nan': '', 'None': ''}).str.strip()
            series_to_combine.append(s)
        else:
            series_to_combine.append(pd.Series([''] * len(df), index=df.index))
            
    # ë¹ˆ ë¬¸ìì—´ì„ ì œì™¸í•˜ê³  ê²°í•©
    combined = [sep.join(filter(None, row)) for row in zip(*series_to_combine)]
    combined = pd.Series(combined, index=df.index, dtype='object')

    # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±° í›„, ìµœì¢…ì ìœ¼ë¡œ ë¹ˆ ë¬¸ìì—´ì„ pd.NAë¡œ ë³€í™˜ (ê²°ê³¼ì ìœ¼ë¡œ nanìœ¼ë¡œ ì €ì¥ë¨)
    return combined.str.replace(r'\s+', ' ', regex=True).str.strip().replace('', pd.NA)


# ----------------------------------------------------------------------
# 3. í•µì‹¬ ì „ì²˜ë¦¬ ë¡œì§ (ê° íŒŒì¼ë³„ 9ë‹¨ê³„ í†µí•©)
# ----------------------------------------------------------------------

def process_all_files(file_map):
    """6ê°œ íŒŒì¼ì„ ì½ê³  ì „ì²˜ë¦¬ ê·œì¹™ì— ë”°ë¼ í•˜ë‚˜ì˜ í†µí•© DataFrameìœ¼ë¡œ ê²°í•©í•©ë‹ˆë‹¤."""
    list_of_dfs = []
    
    def load_file(source_name):
        # ìˆ˜ì •ëœ ë¶€ë¶„: DATA_DIR_PATHë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
        file_name = file_map[source_name]
        data_path = DATA_DIR_PATH / file_name

        # ì „ì²´ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        return pd.read_csv(data_path, sep='\t', encoding='utf-8', na_values=['', ' ', 'nan'], keep_default_na=True)

    # --- 1. ì¹´ì¹´ì˜¤ë±…í¬ (ì´ 9ë‹¨ê³„) ---
    try:
        df_kakao = load_file("ì¹´ì¹´ì˜¤ë±…í¬")
        df_kakao_standard = pd.DataFrame(index=df_kakao.index)
        df_kakao['ê±°ë˜ê¸ˆì•¡_clean'] = clean_amount(df_kakao['ê±°ë˜ê¸ˆì•¡'])

        # 1ë‹¨ê³„: ê±°ë˜ì¼ì‹œ ìƒì„±
        df_kakao_standard['ê±°ë˜ì¼ì‹œ'] = pd.to_datetime(df_kakao['ê±°ë˜ì¼ì‹œ'], format='%Y.%m.%d %H:%M:%S', errors='coerce').dt.strftime('%Y.%m.%d %H:%M:%S').replace('NaT', pd.NA)
        # 2ë‹¨ê³„: ì‚¬ìš©êµ¬ë¶„ ìƒì„±
        df_kakao_standard['ì‚¬ìš©êµ¬ë¶„'] = df_kakao['êµ¬ë¶„'].replace('', pd.NA)
        # 3ë‹¨ê³„: ì‚¬ìš©ë‚´ì—­ ìƒì„±
        df_kakao_standard['ì‚¬ìš©ë‚´ì—­'] = df_kakao['ê±°ë˜êµ¬ë¶„'].replace('', pd.NA)
        # 4ë‹¨ê³„: ê±°ë˜ìƒëŒ€ë°© ìƒì„±
        df_kakao_standard['ê±°ë˜ìƒëŒ€ë°©'] = df_kakao['ë‚´ìš©'].replace('', pd.NA)
        # 5ë‹¨ê³„: ì…ê¸ˆì•¡ ìƒì„±
        df_kakao_standard['ì…ê¸ˆì•¡'] = df_kakao['ê±°ë˜ê¸ˆì•¡_clean'].apply(lambda x: x if x > 0 else 0).astype(float)
        # 6ë‹¨ê³„: ì¶œê¸ˆì•¡ ìƒì„±
        df_kakao_standard['ì¶œê¸ˆì•¡'] = df_kakao['ê±°ë˜ê¸ˆì•¡_clean'].apply(lambda x: abs(x) if x < 0 else 0).astype(float)
        # 7ë‹¨ê³„: ì”ì•¡ ìƒì„±
        df_kakao_standard['ì”ì•¡'] = clean_amount(df_kakao['ê±°ë˜ í›„ ì”ì•¡'])
        # 8ë‹¨ê³„: ë©”ëª¨ ìƒì„±
        df_kakao_standard['ë©”ëª¨'] = df_kakao['ë©”ëª¨'].replace('', pd.NA)
        # 9ë‹¨ê³„: íŒŒì¼ ì¶œì²˜ ì¶”ê°€
        df_kakao_standard['ì¶œì²˜'] = 'ì¹´ì¹´ì˜¤ë±…í¬'
        
        list_of_dfs.append(df_kakao_standard[FINAL_COLUMNS].copy())
    except Exception as e:
        print(f"âš ï¸ [ì¹´ì¹´ì˜¤ë±…í¬] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # --- 2. ì¼€ì´ë±…í¬ (ì´ 9ë‹¨ê³„) ---
    try:
        df_kbank = load_file("ì¼€ì´ë±…í¬")
        df_kbank_standard = pd.DataFrame(index=df_kbank.index)
        df_kbank['ì…ê¸ˆê¸ˆì•¡_clean'] = clean_amount(df_kbank['ì…ê¸ˆê¸ˆì•¡']).fillna(0)
        df_kbank['ì¶œê¸ˆê¸ˆì•¡_clean'] = clean_amount(df_kbank['ì¶œê¸ˆê¸ˆì•¡']).fillna(0)
        
        # 1ë‹¨ê³„: ê±°ë˜ì¼ì‹œ ìƒì„±
        df_kbank_standard['ê±°ë˜ì¼ì‹œ'] = pd.to_datetime(df_kbank['ê±°ë˜ì¼ì‹œ'], format='%Y.%m.%d %H:%M:%S', errors='coerce').dt.strftime('%Y.%m.%d %H:%M:%S').replace('NaT', pd.NA)
        # 2ë‹¨ê³„: ì‚¬ìš©êµ¬ë¶„ ìƒì„±
        df_kbank_standard['ì‚¬ìš©êµ¬ë¶„'] = np.select([df_kbank['ì…ê¸ˆê¸ˆì•¡_clean'] > 0, df_kbank['ì¶œê¸ˆê¸ˆì•¡_clean'] > 0], ['ì…ê¸ˆ', 'ì¶œê¸ˆ'], default=pd.NA) 
        # 3ë‹¨ê³„: ì‚¬ìš©ë‚´ì—­ ìƒì„±
        df_kbank_standard['ì‚¬ìš©ë‚´ì—­'] = combine_and_clean_str(df_kbank, ['ê±°ë˜êµ¬ë¶„', 'ì ìš”ë‚´ìš©'])
        # 4ë‹¨ê³„: ê±°ë˜ìƒëŒ€ë°© ìƒì„±
        df_kbank_standard['ê±°ë˜ìƒëŒ€ë°©'] = combine_and_clean_str(df_kbank, ['ìƒëŒ€ ì€í–‰', 'ìƒëŒ€ ì˜ˆê¸ˆì£¼ëª…', 'ìƒëŒ€ ê³„ì¢Œë²ˆí˜¸'])
        # 5ë‹¨ê³„: ì…ê¸ˆì•¡ ìƒì„±
        df_kbank_standard['ì…ê¸ˆì•¡'] = df_kbank['ì…ê¸ˆê¸ˆì•¡_clean']
        # 6ë‹¨ê³„: ì¶œê¸ˆì•¡ ìƒì„±
        df_kbank_standard['ì¶œê¸ˆì•¡'] = df_kbank['ì¶œê¸ˆê¸ˆì•¡_clean']
        # 7ë‹¨ê³„: ì”ì•¡ ìƒì„±
        df_kbank_standard['ì”ì•¡'] = clean_amount(df_kbank['ì”ì•¡'])
        # 8ë‹¨ê³„: ë©”ëª¨ ìƒì„±
        df_kbank_standard['ë©”ëª¨'] = df_kbank['ë©”ëª¨'].replace('', pd.NA)
        # 9ë‹¨ê³„: íŒŒì¼ ì¶œì²˜ ì¶”ê°€
        df_kbank_standard['ì¶œì²˜'] = 'ì¼€ì´ë±…í¬'
        
        list_of_dfs.append(df_kbank_standard[FINAL_COLUMNS].copy())
    except Exception as e:
        print(f"âš ï¸ [ì¼€ì´ë±…í¬] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # --- 3. í† ìŠ¤ë±…í¬ (ì´ 9ë‹¨ê³„) ---
    try:
        df_toss = load_file("í† ìŠ¤ë±…í¬")
        df_toss_standard = pd.DataFrame(index=df_toss.index)
        df_toss['ê±°ë˜ ê¸ˆì•¡_clean'] = clean_amount(df_toss['ê±°ë˜ ê¸ˆì•¡'])

        # 1ë‹¨ê³„: ê±°ë˜ì¼ì‹œ ìƒì„±
        df_toss_standard['ê±°ë˜ì¼ì‹œ'] = pd.to_datetime(df_toss['ê±°ë˜ ì¼ì‹œ'], format='%Y.%m.%d %H:%M:%S', errors='coerce').dt.strftime('%Y.%m.%d %H:%M:%S').replace('NaT', pd.NA)
        # 2ë‹¨ê³„: ì‚¬ìš©êµ¬ë¶„ ìƒì„±
        deposit_mask = df_toss['ê±°ë˜ ê¸ˆì•¡_clean'] > 0
        withdraw_mask = df_toss['ê±°ë˜ ê¸ˆì•¡_clean'] < 0
        df_toss_standard['ì‚¬ìš©êµ¬ë¶„'] = np.select([deposit_mask, withdraw_mask],['ì…ê¸ˆ_' + df_toss['ê±°ë˜ ìœ í˜•'].astype(str), 'ì¶œê¸ˆ_' + df_toss['ê±°ë˜ ìœ í˜•'].astype(str)],default=pd.NA)
        df_toss_standard['ì‚¬ìš©êµ¬ë¶„'] = df_toss_standard['ì‚¬ìš©êµ¬ë¶„'].str.replace('_nan', '').replace('nan', pd.NA) 
        # 3ë‹¨ê³„: ì‚¬ìš©ë‚´ì—­ ìƒì„±
        df_toss_standard['ì‚¬ìš©ë‚´ì—­'] = combine_and_clean_str(df_toss, ['ê±°ë˜ ê¸°ê´€', 'ì ìš”'])
        # 4ë‹¨ê³„: ê±°ë˜ìƒëŒ€ë°© ìƒì„±
        df_toss_standard['ê±°ë˜ìƒëŒ€ë°©'] = combine_and_clean_str(df_toss, ['ê±°ë˜ ê¸°ê´€', 'ê³„ì¢Œë²ˆí˜¸'])
        # 5ë‹¨ê³„: ì…ê¸ˆì•¡ ìƒì„±
        df_toss_standard['ì…ê¸ˆì•¡'] = df_toss['ê±°ë˜ ê¸ˆì•¡_clean'].apply(lambda x: x if x > 0 else 0).astype(float)
        # 6ë‹¨ê³„: ì¶œê¸ˆì•¡ ìƒì„±
        df_toss_standard['ì¶œê¸ˆì•¡'] = df_toss['ê±°ë˜ ê¸ˆì•¡_clean'].apply(lambda x: abs(x) if x < 0 else 0).astype(float)
        # 7ë‹¨ê³„: ì”ì•¡ ìƒì„±
        df_toss_standard['ì”ì•¡'] = clean_amount(df_toss['ê±°ë˜ í›„ ì”ì•¡'])
        # 8ë‹¨ê³„: ë©”ëª¨ ìƒì„±
        df_toss_standard['ë©”ëª¨'] = df_toss['ë©”ëª¨'].replace('', pd.NA)
        # 9ë‹¨ê³„: íŒŒì¼ ì¶œì²˜ ì¶”ê°€
        df_toss_standard['ì¶œì²˜'] = 'í† ìŠ¤ë±…í¬'
        
        list_of_dfs.append(df_toss_standard[FINAL_COLUMNS].copy())
    except Exception as e:
        print(f"âš ï¸ [í† ìŠ¤ë±…í¬] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # --- 4. í˜„ëŒ€ì¹´ë“œ (ì´ 9ë‹¨ê³„) ---
    try:
        df_hcard = load_file("í˜„ëŒ€ì¹´ë“œ")
        df_hcard_standard = pd.DataFrame(index=df_hcard.index)
        
        # 1ë‹¨ê³„: ê±°ë˜ì¼ì‹œ ìƒì„±
        date_str = df_hcard['ì´ìš©ì¼'].astype(str).str.replace(r'[ë…„ì›”ì¼]', '.', regex=True).str.strip('.')
        datetime_combined = date_str + ' 00:00:00'
        df_hcard_standard['ê±°ë˜ì¼ì‹œ'] = pd.to_datetime(datetime_combined, format='%Y.%m.%d %H:%M:%S', errors='coerce').dt.strftime('%Y.%m.%d %H:%M:%S').replace('NaT', pd.NA)

        df_hcard['ì´ìš©ê¸ˆì•¡_clean'] = clean_amount(df_hcard['ì´ìš©ê¸ˆì•¡']).fillna(0)
        # 2ë‹¨ê³„: ì‚¬ìš©êµ¬ë¶„ ìƒì„±
        df_hcard_standard['ì‚¬ìš©êµ¬ë¶„'] = 'ì¶œê¸ˆ'
        # 3ë‹¨ê³„: ì‚¬ìš©ë‚´ì—­ ìƒì„±
        df_hcard_standard['ì‚¬ìš©ë‚´ì—­'] = combine_and_clean_str(df_hcard, ['ì¹´ë“œêµ¬ë¶„', 'ì¹´ë“œëª…(ì¹´ë“œë²ˆí˜¸ ë’¤ 4ìë¦¬)'])
        # 4ë‹¨ê³„: ê±°ë˜ìƒëŒ€ë°© ìƒì„±
        df_hcard_standard['ê±°ë˜ìƒëŒ€ë°©'] = combine_and_clean_str(df_hcard, ['ê°€ë§¹ì ëª…', 'ì‚¬ì—…ìë²ˆí˜¸'])
        # 5ë‹¨ê³„: ì…ê¸ˆì•¡ ìƒì„±
        df_hcard_standard['ì…ê¸ˆì•¡'] = 0.0
        # 6ë‹¨ê³„: ì¶œê¸ˆì•¡ ìƒì„±
        df_hcard_standard['ì¶œê¸ˆì•¡'] = df_hcard['ì´ìš©ê¸ˆì•¡_clean']
        # 7ë‹¨ê³„: ì”ì•¡ ìƒì„±
        df_hcard_standard['ì”ì•¡'] = pd.NA
        # 8ë‹¨ê³„: ë©”ëª¨ ìƒì„±
        df_hcard_standard['ë©”ëª¨'] = combine_and_clean_str(df_hcard, ['ìŠ¹ì¸ë²ˆí˜¸', 'í• ë¶€ ê°œì›”'])
        # 9ë‹¨ê³„: íŒŒì¼ ì¶œì²˜ ì¶”ê°€
        df_hcard_standard['ì¶œì²˜'] = 'í˜„ëŒ€ì¹´ë“œ'
        
        list_of_dfs.append(df_hcard_standard[FINAL_COLUMNS].copy())
    except Exception as e:
        print(f"âš ï¸ [í˜„ëŒ€ì¹´ë“œ] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # --- 5. ë†í˜‘_í˜œì§„ (ì´ 9ë‹¨ê³„) ---
    try:
        df_nh = load_file("ë†í˜‘_í˜œì§„")
        df_nh_standard = pd.DataFrame(index=df_nh.index)

        # 1ë‹¨ê³„: ê±°ë˜ì¼ì‹œ ìƒì„±
        datetime_series = df_nh['ê±°ë˜ì¼ì‹œ'].astype(str).str.replace(r'[\/\s]+', '.', regex=True).str.strip('.')
        df_nh_standard['ê±°ë˜ì¼ì‹œ'] = pd.to_datetime(datetime_series, format='%Y.%m.%d %H:%M:%S', errors='coerce').dt.strftime('%Y.%m.%d %H:%M:%S').replace('NaT', pd.NA)
        
        df_nh['ì…ê¸ˆê¸ˆì•¡_clean'] = clean_amount(df_nh['ì…ê¸ˆê¸ˆì•¡']).fillna(0)
        df_nh['ì¶œê¸ˆê¸ˆì•¡_clean'] = clean_amount(df_nh['ì¶œê¸ˆê¸ˆì•¡']).fillna(0)
        # 2ë‹¨ê³„: ì‚¬ìš©êµ¬ë¶„ ìƒì„±
        df_nh_standard['ì‚¬ìš©êµ¬ë¶„'] = np.select([df_nh['ì…ê¸ˆê¸ˆì•¡_clean'] > 0, df_nh['ì¶œê¸ˆê¸ˆì•¡_clean'] > 0], ['ì…ê¸ˆ', 'ì¶œê¸ˆ'], default=pd.NA)
        # 3ë‹¨ê³„: ì‚¬ìš©ë‚´ì—­ ìƒì„±
        df_nh_standard['ì‚¬ìš©ë‚´ì—­'] = df_nh['ê±°ë˜ë‚´ìš©'].replace('', pd.NA)
        # 4ë‹¨ê³„: ê±°ë˜ìƒëŒ€ë°© ìƒì„±
        df_nh_standard['ê±°ë˜ìƒëŒ€ë°©'] = combine_and_clean_str(df_nh, ['ê±°ë˜ê¸°ë¡ì‚¬í•­', 'ê±°ë˜ì '])
        # 5ë‹¨ê³„: ì…ê¸ˆì•¡ ìƒì„±
        df_nh_standard['ì…ê¸ˆì•¡'] = df_nh['ì…ê¸ˆê¸ˆì•¡_clean']
        # 6ë‹¨ê³„: ì¶œê¸ˆì•¡ ìƒì„±
        df_nh_standard['ì¶œê¸ˆì•¡'] = df_nh['ì¶œê¸ˆê¸ˆì•¡_clean']
        # 7ë‹¨ê³„: ì”ì•¡ ìƒì„±
        df_nh_standard['ì”ì•¡'] = clean_amount(df_nh['ê±°ë˜í›„ì”ì•¡'])
        # 8ë‹¨ê³„: ë©”ëª¨ ìƒì„±
        df_nh_standard['ë©”ëª¨'] = df_nh['ê±°ë˜ë©”ëª¨'].replace('', pd.NA)
        # 9ë‹¨ê³„: íŒŒì¼ ì¶œì²˜ ì¶”ê°€
        df_nh_standard['ì¶œì²˜'] = 'ë†í˜‘_í˜œì§„'
        
        list_of_dfs.append(df_nh_standard[FINAL_COLUMNS].copy())
    except Exception as e:
        print(f"âš ï¸ [ë†í˜‘_í˜œì§„] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # --- 6. ì‹ í•œì€í–‰ (ì´ 9ë‹¨ê³„) ---
    try:
        df_shinhan = load_file("ì‹ í•œì€í–‰")
        df_shinhan_standard = pd.DataFrame(index=df_shinhan.index)
        df_shinhan.columns = df_shinhan.columns.str.replace(r'\(ì›\)', '', regex=True).str.strip()
        
        # 1ë‹¨ê³„: ê±°ë˜ì¼ì‹œ ìƒì„±
        datetime_combined = df_shinhan['ê±°ë˜ì¼ì'].astype(str) + ' ' + df_shinhan['ê±°ë˜ì‹œê°„'].astype(str)
        df_shinhan_standard['ê±°ë˜ì¼ì‹œ'] = pd.to_datetime(datetime_combined, format='%Y-%m-%d %H:%M:%S', errors='coerce').dt.strftime('%Y.%m.%d %H:%M:%S').replace('NaT', pd.NA)

        df_shinhan['ì…ê¸ˆ_clean'] = clean_amount(df_shinhan['ì…ê¸ˆ']).fillna(0)
        df_shinhan['ì¶œê¸ˆ_clean'] = clean_amount(df_shinhan['ì¶œê¸ˆ']).fillna(0)
        # 2ë‹¨ê³„: ì‚¬ìš©êµ¬ë¶„ ìƒì„±
        df_shinhan_standard['ì‚¬ìš©êµ¬ë¶„'] = np.select([df_shinhan['ì…ê¸ˆ_clean'] > 0, df_shinhan['ì¶œê¸ˆ_clean'] > 0], ['ì…ê¸ˆ', 'ì¶œê¸ˆ'], default=pd.NA)
        # 3ë‹¨ê³„: ì‚¬ìš©ë‚´ì—­ ìƒì„±
        df_shinhan_standard['ì‚¬ìš©ë‚´ì—­'] = combine_and_clean_str(df_shinhan, ['ì ìš”', 'ë‚´ìš©'])
        # 4ë‹¨ê³„: ê±°ë˜ìƒëŒ€ë°© ìƒì„±
        df_shinhan_standard['ê±°ë˜ìƒëŒ€ë°©'] = combine_and_clean_str(df_shinhan, ['ë‚´ìš©', 'ê±°ë˜ì '])
        # 5ë‹¨ê³„: ì…ê¸ˆì•¡ ìƒì„±
        df_shinhan_standard['ì…ê¸ˆì•¡'] = df_shinhan['ì…ê¸ˆ_clean']
        # 6ë‹¨ê³„: ì¶œê¸ˆì•¡ ìƒì„±
        df_shinhan_standard['ì¶œê¸ˆì•¡'] = df_shinhan['ì¶œê¸ˆ_clean']
        # 7ë‹¨ê³„: ì”ì•¡ ìƒì„±
        df_shinhan_standard['ì”ì•¡'] = clean_amount(df_shinhan['ì”ì•¡'])
        # 8ë‹¨ê³„: ë©”ëª¨ ìƒì„±
        df_shinhan_standard['ë©”ëª¨'] = pd.NA
        # 9ë‹¨ê³„: íŒŒì¼ ì¶œì²˜ ì¶”ê°€
        df_shinhan_standard['ì¶œì²˜'] = 'ì‹ í•œì€í–‰'
        
        list_of_dfs.append(df_shinhan_standard[FINAL_COLUMNS].copy())
    except Exception as e:
        print(f"âš ï¸ [ì‹ í•œì€í–‰] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    
    # ìµœì¢… í†µí•© ë° íƒ€ì… ì •ë¦¬
    if list_of_dfs:
        df_combined = pd.concat(list_of_dfs, ignore_index=True)
        # ë‚ ì§œ íƒ€ì… ì¬ì •ì˜ (ì •ë ¬ ë° ë¶„ì„ ìš©ì´)
        df_combined['ê±°ë˜ì¼ì‹œ'] = pd.to_datetime(df_combined['ê±°ë˜ì¼ì‹œ'], format='%Y.%m.%d %H:%M:%S', errors='coerce')
        df_combined['ì…ê¸ˆì•¡'] = df_combined['ì…ê¸ˆì•¡'].astype(float)
        df_combined['ì¶œê¸ˆì•¡'] = df_combined['ì¶œê¸ˆì•¡'].astype(float)
        return df_combined
    else:
        return pd.DataFrame(columns=FINAL_COLUMNS)

# ----------------------------------------------------------------------
# 4. ë©”ì¸ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ (ì €ì¥ ë° ë¶„ì„ ëª¨ë“œ í†µí•©)
# ----------------------------------------------------------------------

def run_data_integration_pipeline():
    """
    1. 6ê°œ ì›ì²œ íŒŒì¼ì„ í†µí•© ë° ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    2. í†µí•©ëœ DataFrameì„ 'log/' ê²½ë¡œì— íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì°íŒ TSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    3. í†µí•©ëœ DataFrameì„ ë°˜í™˜í•˜ì—¬ ì¦‰ì‹œ ë¶„ì„ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    """
    
    # 4.1. íŒŒì¼ ì²˜ë¦¬ ë° í†µí•©
    final_df = process_all_files(FILE_MAP) 

    if final_df.empty:
        print("\n**í†µí•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.**")
        return None
        
    # 4.2. ìµœì¢… ì •ë ¬
    # ê±°ë˜ ì¼ì‹œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹ ìˆœ ì •ë ¬
    final_df = final_df.sort_values(by='ê±°ë˜ì¼ì‹œ', ascending=False).reset_index(drop=True)

    # 4.3. íŒŒì¼ ì €ì¥ (ì‚¬ìš©ì ìš”ì²­: tsv íŒŒì¼ë¡œ ì €ì¥)
    print("\n" + "="*50)
    print("## âœ… ê¸ˆìœµ ê±°ë˜ ë‚´ì—­ í†µí•© ë° íŒŒì¼ ì €ì¥")
    
    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
    output_file_name = f'integrated_transactions_{timestamp}.tsv'
    output_path = LOG_DIR_PATH / output_file_name 
    
    try:
        final_df.to_csv(output_path, sep='\t', index=False, encoding='utf-8')
        print(f"**ì´ ê±°ë˜ ê±´ìˆ˜:** {len(final_df)}ê±´")
        print(f"**ğŸ’¾ í†µí•© ë°ì´í„° ì „ì²´ ë‚´ì—­ì„ TSV íŒŒì¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.**")
        print(f"**ì €ì¥ ê²½ë¡œ:** {output_path}")
    except Exception as e:
        print(f"\nâš ï¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    # 4.4. ë°ì´í„° ë¶„ì„ ì¤€ë¹„ (DataFrame ë°˜í™˜)
    print("\n## âœ¨ ë°ì´í„° ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ")
    print("**í†µí•©ëœ DataFrameì„ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë°˜í™˜í•©ë‹ˆë‹¤.**")
    print("="*50)
    
    return final_df


if __name__ == "__main__":
    integrated_data = run_data_integration_pipeline() 
    
    if integrated_data is not None:
        print("\n\n*ì´ì œ 'integrated_data' ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.*")
    pass